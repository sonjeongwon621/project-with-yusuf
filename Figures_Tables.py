#!/usr/bin/env python
# coding: utf-8

# In[1]:


# This cell has a bit of initial setup. You can click the triangle to the left to expand it.
# Click the "Run" button immediately above the notebook in order to execute the contents of any cell
# WARNING: Each cell in the notebook relies upon results generated by previous cells
#   The most common problem beginners have is to execute a cell before all its predecessors
#   If you do this, you can restart the kernel (see the "Kernel" menu above) and start over
#get_ipython().run_line_magic('matplotlib', 'inline')
import matplotlib.pyplot as plt

# The first step is to be able to bring things in from different directories
import sys 
import os

sys.path.insert(0, os.path.abspath('../lib'))

#from util import log_progress

import numpy as np
import HARK 
from time import clock
from copy import deepcopy
mystr = lambda number : "{:.4f}".format(number)
from HARK.utilities import plotFuncs


# In[2]:


# Define a parameter dictionary with baseline parameter values

# Set the baseline parameter values 
PermGroFac = 1.02
Rfree      = 1
DiscFac    = 0.96
CRRA       = 2.00
UnempPrb   = 0.005
IncUnemp   = 0.0
PermShkStd = 0.1
TranShkStd = 0.1
# Import default parameter values
import HARK.ConsumptionSaving.ConsumerParameters as Params 

# Make a dictionary containing all parameters needed to solve the model
base_params = Params.init_idiosyncratic_shocks

# Set the parameters for the baseline results in the paper
# using the variable values defined in the cell above
base_params['PermGroFac'] = [PermGroFac]   # Permanent income growth factor
base_params['Rfree']      = Rfree          # Interest factor on assets
base_params['DiscFac']    = DiscFac        # Time Preference Factor
base_params['CRRA']       = CRRA           # Coefficient of relative risk aversion
base_params['UnempPrb']   = UnempPrb       # Probability of unemployment (e.g. Probability of Zero Income in the paper)
base_params['IncUnemp']   = IncUnemp       # Induces natural borrowing constraint
base_params['PermShkStd'] = [PermShkStd]   # Standard deviation of log permanent income shocks
base_params['TranShkStd'] = [TranShkStd]   # Standard deviation of log transitory income shocks

# Some technical settings that are not interesting for our purposes
base_params['LivPrb']       = [1.0]   # 100 percent probability of living to next period
base_params['CubicBool']    = True    # Use cubic spline interpolation
base_params['T_cycle']      = 1       # No 'seasonal' cycles
base_params['BoroCnstArt']  = None    # No artificial borrowing constraint


# In[3]:


from HARK.ConsumptionSaving.ConsIndShockModel import IndShockConsumerType
baseEx_inf = IndShockConsumerType(cycles=0,**base_params)

baseEx_inf.solve()
baseEx_inf.unpackcFunc()


# In[4]:


# Define a function to calculate expected consumption 
def exp_consumption(a):
    '''
    Taking end-of-period assets as input, return expectation of next period's consumption
    Inputs:
       a: end-of-period assets
    Returns:
       expconsump: next period's expected consumption
    '''
    GrowFactp1 = baseEx_inf.PermGroFac[0]* baseEx_inf.PermShkDstn[0][1]
    Rnrmtp1 = baseEx_inf.Rfree / GrowFactp1
    # end-of-period assets plus normalized returns
    btp1 = Rnrmtp1*a
    # expand dims of btp1 and use broadcasted sum of a column and a row vector
    # to obtain a matrix of possible beginning-of-period assets next period
    mtp1 = np.expand_dims(btp1, axis=1) + baseEx_inf.TranShkDstn[0][1]
    part_expconsumption = GrowFactp1*baseEx_inf.cFunc[0](mtp1).T
    # finish expectation over permanent income shocks by right multiplying with
    # the weights
    part_expconsumption = np.dot(part_expconsumption, baseEx_inf.PermShkDstn[0][0])
    # finish expectation over transitory income shocks by right multiplying with
    # weights
    expconsumption = np.dot(part_expconsumption, baseEx_inf.TranShkDstn[0][0])
    # return expected consumption
    return expconsumption


# In[5]:


# Calculate the expected consumption growth factor
m1 = np.linspace(1,baseEx_inf.solution[0].mNrmSS,50) # m1 defines the plot range on the left of target m value (e.g. m <= target m)
c_m1 = baseEx_inf.cFunc[0](m1)
a1 = m1-c_m1
exp_consumption_l1 = [exp_consumption(i) for i in a1]

# growth1 defines the values of expected consumption growth factor when m is less than target m
growth1 = np.array(exp_consumption_l1)/c_m1

# m2 defines the plot range on the right of target m value (e.g. m >= target m)
m2 = np.linspace(baseEx_inf.solution[0].mNrmSS,1.9,50)

c_m2 = baseEx_inf.cFunc[0](m2)
a2 = m2-c_m2
exp_consumption_l2 = [exp_consumption(i) for i in a2]

# growth 2 defines the values of expected consumption growth factor when m is bigger than target m
growth2 = np.array(exp_consumption_l2)/c_m2


# In[6]:


# Define a function to construct the arrows on the consumption growth rate function
def arrowplot(axes, x, y, narrs=15, dspace=0.5, direc='neg',
              hl=0.01, hw=3, c='black'):
    '''
    The function is used to plot arrows given the data x and y.

    Input:
        narrs  :  Number of arrows that will be drawn along the curve

        dspace :  Shift the position of the arrows along the curve.
                  Should be between 0. and 1.

        direc  :  can be 'pos' or 'neg' to select direction of the arrows

        hl     :  length of the arrow head

        hw     :  width of the arrow head

        c      :  color of the edge and face of the arrow head
    '''

    # r is the distance spanned between pairs of points
    r = np.sqrt(np.diff(x)**2+np.diff(y)**2)
    r = np.insert(r, 0, 0.0)

    # rtot is a cumulative sum of r, it's used to save time
    rtot = np.cumsum(r)

    # based on narrs set the arrow spacing
    aspace = r.sum() / narrs

    if direc is 'neg':
        dspace = -1.*abs(dspace)
    else:
        dspace = abs(dspace)

    arrowData = [] # will hold tuples of x,y,theta for each arrow
    arrowPos = aspace*(dspace) # current point on walk along data
                                 # could set arrowPos to 0 if you want
                                 # an arrow at the beginning of the curve

    ndrawn = 0
    rcount = 1
    while arrowPos < r.sum() and ndrawn < narrs:
        x1,x2 = x[rcount-1],x[rcount]
        y1,y2 = y[rcount-1],y[rcount]
        da = arrowPos-rtot[rcount]
        theta = np.arctan2((x2-x1),(y2-y1))
        ax = np.sin(theta)*da+x1
        ay = np.cos(theta)*da+y1
        arrowData.append((ax,ay,theta))
        ndrawn += 1
        arrowPos+=aspace
        while arrowPos > rtot[rcount+1]:
            rcount+=1
            if arrowPos > rtot[-1]:
                break

    for ax,ay,theta in arrowData:
        # use aspace as a guide for size and length of things
        # scaling factors were chosen by experimenting a bit

        dx0 = np.sin(theta)*hl/2.0 + ax
        dy0 = np.cos(theta)*hl/2.0 + ay
        dx1 = -1.*np.sin(theta)*hl/2.0 + ax
        dy1 = -1.*np.cos(theta)*hl/2.0 + ay

        if direc is 'neg' :
            ax0 = dx0
            ay0 = dy0
            ax1 = dx1
            ay1 = dy1
        else:
            ax0 = dx1
            ay0 = dy1
            ax1 = dx0
            ay1 = dy0

        axes.annotate('', xy=(ax0, ay0), xycoords='data',
                xytext=(ax1, ay1), textcoords='data',
                arrowprops=dict( headwidth=hw, frac=1., ec=c, fc=c))


# In[7]:


# Plot consumption growth as a function of market resources
# Calculate Absolute Patience Factor Phi = lower bound of consumption growth factor
import math

AbsPatientFac = math.log((baseEx_inf.Rfree*baseEx_inf.DiscFac)**(1.0/baseEx_inf.CRRA))

fig = plt.figure(figsize = (12,8))
ax = fig.add_subplot(111)
# Plot the Absolute Patience Factor line
ax.plot([0,2.0],[AbsPatientFac,AbsPatientFac], label=r'Absolute Patience Rate: $\rho^{-1}(r-\delta)$')

# Plot the Permanent Income Growth Factor line
ax.plot([0,2.0],[math.log(baseEx_inf.PermGroFac[0]),math.log(baseEx_inf.PermGroFac[0])], label=r'Permanent Income Growth Rate: $g$')

# Plot the expected consumption growth factor on the left side of target m
ax.plot(m1,np.log(growth1),color="black", label=r'Expected Consumption Growth Rate: $E_t\Delta \log C_{t+1}$')

# Plot the expected consumption growth factor on the right side of target m
ax.plot(m2,np.log(growth2),color="black")

# Plot the arrows
arrowplot(ax, m1,np.log(growth1))
arrowplot(ax, m2,np.log(growth2), direc='pos')

# Plot the target m
ax.plot([baseEx_inf.solution[0].mNrmSS,baseEx_inf.solution[0].mNrmSS],[-1,1.4],color="red", label='Target Level of Wealth')
ax.set_xlim(1,1.9)
ax.set_ylim(-0.05,0.05)
#ax.set_ylim(0.98,1.08)
plt.xlabel('$m_t$', fontsize=20)
plt.ylabel('Growth', fontsize=20)
plt.legend()
plt.savefig('Figures/Figure1a.png')

# In[8]:


# Define a parameter dictionary with baseline parameter values

# Set the baseline parameter values 
PermGroFac = 1.005
Rfree      = 1
DiscFac    = 0.96
CRRA       = 2.00
UnempPrb   = 0.005
IncUnemp   = 0.0
PermShkStd = 0.1
TranShkStd = 0.1
# Import default parameter values
import HARK.ConsumptionSaving.ConsumerParameters as Params 

# Make a dictionary containing all parameters needed to solve the model
base_params1 = Params.init_idiosyncratic_shocks

# Set the parameters for the baseline results in the paper
# using the variable values defined in the cell above
base_params1['PermGroFac'] = [PermGroFac]   # Permanent income growth factor
base_params1['Rfree']      = Rfree          # Interest factor on assets
base_params1['DiscFac']    = DiscFac        # Time Preference Factor
base_params1['CRRA']       = CRRA           # Coefficient of relative risk aversion
base_params1['UnempPrb']   = UnempPrb       # Probability of unemployment (e.g. Probability of Zero Income in the paper)
base_params1['IncUnemp']   = IncUnemp       # Induces natural borrowing constraint
base_params1['PermShkStd'] = [PermShkStd]   # Standard deviation of log permanent income shocks
base_params1['TranShkStd'] = [TranShkStd]   # Standard deviation of log transitory income shocks

# Some technical settings that are not interesting for our purposes
base_params1['LivPrb']       = [1.0]   # 100 percent probability of living to next period
base_params1['CubicBool']    = True    # Use cubic spline interpolation
base_params1['T_cycle']      = 1       # No 'seasonal' cycles
base_params1['BoroCnstArt']  = None    # No artificial borrowing constraint


# In[9]:


from HARK.ConsumptionSaving.ConsIndShockModel import IndShockConsumerType
baseEx_inf1 = IndShockConsumerType(cycles=0,**base_params1)

baseEx_inf1.solve()
baseEx_inf1.unpackcFunc()


# In[10]:


# Define a function to calculate expected consumption 
def exp_consumption(a):
    '''
    Taking end-of-period assets as input, return expectation of next period's consumption
    Inputs:
       a: end-of-period assets
    Returns:
       expconsump: next period's expected consumption
    '''
    GrowFactp1 = baseEx_inf1.PermGroFac[0]* baseEx_inf1.PermShkDstn[0][1]
    Rnrmtp1 = baseEx_inf1.Rfree / GrowFactp1
    # end-of-period assets plus normalized returns
    btp1 = Rnrmtp1*a
    # expand dims of btp1 and use broadcasted sum of a column and a row vector
    # to obtain a matrix of possible beginning-of-period assets next period
    mtp1 = np.expand_dims(btp1, axis=1) + baseEx_inf1.TranShkDstn[0][1]
    part_expconsumption = GrowFactp1*baseEx_inf1.cFunc[0](mtp1).T
    # finish expectation over permanent income shocks by right multiplying with
    # the weights
    part_expconsumption = np.dot(part_expconsumption, baseEx_inf1.PermShkDstn[0][0])
    # finish expectation over transitory income shocks by right multiplying with
    # weights
    expconsumption = np.dot(part_expconsumption, baseEx_inf1.TranShkDstn[0][0])
    # return expected consumption
    return expconsumption


# In[11]:


# Calculate the expected consumption growth factor
m11 = np.linspace(1,baseEx_inf1.solution[0].mNrmSS,50) # m1 defines the plot range on the left of target m value (e.g. m <= target m)
c_m11 = baseEx_inf1.cFunc[0](m11)
a11 = m11-c_m11
exp_consumption_l11 = [exp_consumption(i) for i in a11]

# growth1 defines the values of expected consumption growth factor when m is less than target m
growth11 = np.array(exp_consumption_l11)/c_m11

# m2 defines the plot range on the right of target m value (e.g. m >= target m)
m21 = np.linspace(baseEx_inf1.solution[0].mNrmSS,1.9,50)

c_m21 = baseEx_inf1.cFunc[0](m21)
a21 = m21-c_m21
exp_consumption_l21 = [exp_consumption(i) for i in a21]

# growth 2 defines the values of expected consumption growth factor when m is bigger than target m
growth21 = np.array(exp_consumption_l21)/c_m21


# In[12]:


# Plot consumption growth as a function of market resources
# Calculate Absolute Patience Factor Phi = lower bound of consumption growth factor
AbsPatientFac1 = math.log((baseEx_inf1.Rfree)*(baseEx_inf1.DiscFac)**(1.0/baseEx_inf1.CRRA))

fig = plt.figure(figsize = (12,8))
ax = fig.add_subplot(111)
# Plot the Absolute Patience Factor line
ax.plot([0,1.9],[AbsPatientFac1,AbsPatientFac1],label=r'Absolute Patience Rate: $\rho^{-1}(r-\delta)$')
#ax.plot([0,1.9],[AbsPatientFac,AbsPatientFac],color="red")

# Plot the Permanent Income Growth Factor line
ax.plot([0,1.9],[math.log(baseEx_inf1.PermGroFac[0]),math.log(baseEx_inf1.PermGroFac[0])], label=r'Permanent Income Growth Rate: $g_2$', color='orange', linestyle="--")
ax.plot([0,1.9],[math.log(baseEx_inf.PermGroFac[0]),math.log(baseEx_inf.PermGroFac[0])], label=r'Permanent Income Growth Rate: $g_1$', color='orange')

# Plot the expected consumption growth factor on the left side of target m
ax.plot(m11,np.log(growth11),color="black",linestyle="--", label=r'Expected Consumption Growth Rate under $g_2$')
ax.plot(m1,np.log(growth1),color="black", label=r'Expected Consumption Growth Rate under $g_1$')

# Plot the expected consumption growth factor on the right side of target m
ax.plot(m21,np.log(growth21),color="black", linestyle="--")
ax.plot(m2,np.log(growth2),color="black")

# Plot the arrows
#arrowplot(ax, m1,np.log(growth1))
#arrowplot(ax, m2,np.log(growth2), direc='pos')

# Plot the target m
ax.plot([baseEx_inf1.solution[0].mNrmSS,baseEx_inf1.solution[0].mNrmSS],[-0.05,0.05],color="red",linestyle="--", label='Target Level of Wealth under $g_2$')
ax.plot([baseEx_inf.solution[0].mNrmSS,baseEx_inf.solution[0].mNrmSS],[-0.05,0.05],color="red", label='Target Level of Wealth under $g_1$')

ax.set_xlim(0.9,1.9)
ax.set_ylim(-0.05,0.05)
plt.xlabel('$m_t$',fontsize=20)
plt.ylabel('Growth',fontsize=20)
plt.legend()
plt.savefig('Figures/Figure1b.png')

# In[13]:


import HARK.ConsumptionSaving.ConsIndShockModel as Model        # The consumption-saving micro model
import HARK.ConsumptionSaving.ConsumerParameters as Params    # Parameters for the consumer type
from HARK.utilities import plotFuncsDer, plotFuncs              # Some tools
from time import time
mystr = lambda number : "{:.4f}".format(number)
do_simulation = True
import numpy as np
import matplotlib.pyplot as plt

#Notebooks to look for helpful code
# https://github.com/econ-ark/HARK/blob/master/HARK/SolvingMicroDSOPs/Code/StructEstimation.py
# https://github.com/econ-ark/HARK/blob/master/HARK/ConsumptionSaving/ConsIndShockModel.py
# https://github.com/econ-ark/HARK/blob/master/HARK/ConsumptionSaving/ConsumerParameters.py
# https://github.com/matthew-zahn/CGMPort/blob/develop/REMARK/CGM_REMARK.ipynb


# In[14]:


#Set Parameters

Params.init_lifecycle["CRRA"]= 2.00            # Default coefficient of relative risk aversion (rho)
Params.init_lifecycle["DiscFac"]= 0.96         # Default intertemporal discount factor (beta)
Params.init_lifecycle["PermGroFacAgg"]= 1.02    # Aggregate permanent income growth factor 
Params.init_lifecycle["aNrmInitMean"]= -1000       # Mean of log initial assets 
Params.init_lifecycle["aNrmInitStd"]= 0.0      # Standard deviation of log initial assets
Params.init_lifecycle["pLvlInitMean"]= 0.0     # Mean of log initial permanent income
Params.init_lifecycle["pLvlInitStd"]= 0.0      # Standard deviation of log initial permanent income
Params.init_lifecycle["Rfree"]= 1.00

Params.init_lifecycle['AgentCount'] = 10000                 #Change the number of agents simulated from default 10000 to 1000

Params.init_lifecycle['PermShkStd'] = [0.1]*40 + [0]*9               #Originally, [0.1,0.2,0.1,0.2,0.1,0.2,0.1,0,0,0]
Params.init_lifecycle['TranShkStd'] = [0.1]*40 + [0]*9               #Originally, [0.3,0.2,0.1,0.3,0.2,0.1,0.3,0,0,0]
Params.init_lifecycle['LivPrb']     = [1]*49                 #Originally, [0.99,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1]
Params.init_lifecycle['T_cycle']    = 49                     #Life starts at age 25 and ends at 75. Originally 10
Params.init_lifecycle['T_retire']   = 40                    #Agents retire at age 65. Originally 7
Params.init_lifecycle['T_age']      = 50                    #Make sure that old people die at terminal age and don't turn into newborns! Originally 11


# In[15]:


#Unskilled Laborers: 3 percent growth from 25~40. flat for 40~65.

Params.init_lifecycle["pLvlInitMean"]= -0.0296  #This is set to log(1/1.03) since agents receive their first period permanent income with the growth factor considered.
Params.init_lifecycle['PermGroFac'] = [1.03]*14 + [1]*25 + [0.7] + [1]*9     #Oringinally, [1.01,1.01,1.01,1.01,1.01,1.02,1.02,1.02,1.02,1.02]

Lifecycle_Unskilled = Model.IndShockConsumerType(**Params.init_lifecycle)
Lifecycle_Unskilled.cycles = 1 #1 for finite horizon and 0 for infinite horizon
Lifecycle_Unskilled.solve()
Lifecycle_Unskilled.unpackcFunc()
Lifecycle_Unskilled.timeFwd() #make sure that time is moving forward


# In[16]:


#Operatives: 2.5 percent growth from 25~50. 1 percent growth from 50~65.
Params.init_lifecycle["pLvlInitMean"]= -0.0198 #This is set to log(1/1.025) since agents receive their first period permanent income with the growth factor considered.
Params.init_lifecycle['PermGroFac'] = [1.025]*24 + [1.01]*15 + [0.7] + [1]*9     #Oringinally, [1.01,1.01,1.01,1.01,1.01,1.02,1.02,1.02,1.02,1.02]

Lifecycle_Operatives = Model.IndShockConsumerType(**Params.init_lifecycle)
Lifecycle_Operatives.cycles = 1 #1 for finite horizon and 0 for infinite horizon
Lifecycle_Operatives.solve()
Lifecycle_Operatives.unpackcFunc()
Lifecycle_Operatives.timeFwd() #make sure that time is moving forward


# In[17]:


#Managers: 3 percent growth from 25~55. 1 percent decline from 55~65.
Params.init_lifecycle["pLvlInitMean"]= -0.0296 #This is set to log(1/1.03) since agents receive their first period permanent income with the growth factor considered.
Params.init_lifecycle['PermGroFac'] = [1.03]*29 + [0.99]*10 + [0.7] + [1]*9     #Oringinally, [1.01,1.01,1.01,1.01,1.01,1.02,1.02,1.02,1.02,1.02]

Lifecycle_Managers = Model.IndShockConsumerType(**Params.init_lifecycle)
Lifecycle_Managers.cycles = 1 #1 for finite horizon and 0 for infinite horizon
Lifecycle_Managers.solve()
Lifecycle_Managers.unpackcFunc()
Lifecycle_Managers.timeFwd() #make sure that time is moving forward


# In[18]:


#This is only for showing the consumption function so we don't need to have it run

#print('Consumption functions while working:')


#mMin = min([Lifecycle_Unskilled.solution[t].mNrmMin for t in range(Lifecycle_Unskilled.T_cycle)])
   #Finds the minimum of Lifecycle_Unskilled.solution[t].mNrmMin for t = 0~49
   #mNrmMin: The minimum allowable market resources for this period; the consumption function (etc) are undefined for m < mNrmMin.


#plotFuncs(Lifecycle_Unskilled.cFunc[:Lifecycle_Unskilled.T_retire],mMin,5)
   #This plots the consumption function for life periods 0~40. Plots it with respect to wealth from 0 to 5.
   #The highest curve is for period 0.

#print('Consumption functions while retired:')
#plotFuncs(Lifecycle_Unskilled.cFunc[Lifecycle_Unskilled.T_retire:],0,5)
   #Highest graph represents consumption in last period. MPC is 1 since the consumer consumes everything in the second to last period.

#Lifecycle_Unskilled.timeRev()
   #Set time to reverse so that simulations solve using backward induction


# In[19]:


if do_simulation:
    Lifecycle_Unskilled.T_sim = 49 #simulate Lifecycle_Unskilled.T_sim periods for 10000(default) agents
    Lifecycle_Unskilled.track_vars = ['aNrmNow','mNrmNow','cNrmNow','pLvlNow','t_age'] #track these variables
    Lifecycle_Unskilled.initializeSim()
    Lifecycle_Unskilled.simulate()
    
if do_simulation:
    Lifecycle_Operatives.T_sim = 49 #simulate Lifecycle_Unskilled.T_sim periods for 10000(default) agents
    Lifecycle_Operatives.track_vars = ['aNrmNow','mNrmNow','cNrmNow','pLvlNow','t_age'] #track these variables
    Lifecycle_Operatives.initializeSim()
    Lifecycle_Operatives.simulate()

if do_simulation:
    Lifecycle_Managers.T_sim = 49 #simulate Lifecycle_Unskilled.T_sim periods for 10000(default) agents
    Lifecycle_Managers.track_vars = ['aNrmNow','mNrmNow','cNrmNow','pLvlNow','t_age'] #track these variables
    Lifecycle_Managers.initializeSim()
    Lifecycle_Managers.simulate()


# In[20]:


import pandas as pd
raw_data = {'T_age': Lifecycle_Unskilled.t_age_hist.flatten()+24, #add 24 to make the starting period 25. age is same for all occupations so so need to make three of these.
            'cNrmNow_Unskilled': Lifecycle_Unskilled.cNrmNow_hist.flatten(),
            'pLvlNow_Unskilled': Lifecycle_Unskilled.pLvlNow_hist.flatten(),
            'mNrmNow_Unskilled': Lifecycle_Unskilled.mNrmNow_hist.flatten(),
            'cNrmNow_Operatives': Lifecycle_Operatives.cNrmNow_hist.flatten(),
            'pLvlNow_Operatives': Lifecycle_Operatives.pLvlNow_hist.flatten(),
            'mNrmNow_Operatives': Lifecycle_Operatives.mNrmNow_hist.flatten(),
            'aNrmNow_Operatives': Lifecycle_Operatives.aNrmNow_hist.flatten(),
            'cNrmNow_Managers': Lifecycle_Managers.cNrmNow_hist.flatten(),
            'pLvlNow_Managers': Lifecycle_Managers.pLvlNow_hist.flatten(),
            'mNrmNow_Managers': Lifecycle_Managers.mNrmNow_hist.flatten(),}

#Make the simulated results into a dataset

Data = pd.DataFrame(raw_data) #make the raw data into a formal dataset
Data['Cons_Unskilled'] = Data.cNrmNow_Unskilled * Data.pLvlNow_Unskilled #cNrmNow has to be multiplied by pLvlNow
Data['Cons_Operatives'] = Data.cNrmNow_Operatives * Data.pLvlNow_Operatives
Data['Cons_Managers'] = Data.cNrmNow_Managers * Data.pLvlNow_Managers
Data['wealth'] = Data.aNrmNow_Operatives

Data['Inc_Unskilled'] = Data.pLvlNow_Unskilled
Data['Inc_Operatives'] = Data.pLvlNow_Operatives 
Data['Inc_Managers'] = Data.pLvlNow_Managers
#Data['M'] = Data.nrmM * Data.pIncome

AgeMeans = Data.groupby(['T_age']).mean().reset_index() # Group the dataset by T_age and get the mean.


# In[21]:


plt.figure()

plt.plot(AgeMeans.T_age, AgeMeans.Cons_Unskilled,label='Consumption')
plt.plot(AgeMeans.T_age, AgeMeans.Inc_Unskilled,label='Income')

plt.legend()
plt.xlabel('Age')
plt.title('Unskilled Laborers')
plt.ylim(0.8,2.5)
plt.savefig('Figures/Figure5a.png')

plt.figure()

plt.plot(AgeMeans.T_age, AgeMeans.Cons_Operatives,label='Consumption')
plt.plot(AgeMeans.T_age, AgeMeans.Inc_Operatives, label='Income')
#plt.plot(AgeMeans.T_age, AgeMeans.wealth, label='wealth')

plt.legend()
plt.xlabel('Age')
plt.title('Operatives')
plt.ylim(0.8,2.5)
plt.savefig('Figures/Figure5b.png')

plt.figure()

plt.plot(AgeMeans.T_age, AgeMeans.Cons_Managers,label='Consumption')
plt.plot(AgeMeans.T_age, AgeMeans.Inc_Managers, label='Income')

plt.legend()
plt.xlabel('Age')
plt.title('Managers')
plt.ylim(0.8,2.5)
plt.savefig('Figures/Figure5c.png')

# In[22]:


# Figure VII
Params.init_lifecycle["pLvlInitMean"]= -0.0198 #This is set to log(1/1.025) since agents receive their first period permanent income with the growth factor considered.
Params.init_lifecycle['PermGroFac'] = [1.025]*24 + [1.01]*15 + [0.7] + [1]*9     #Oringinally, [1.01,1.01,1.01,1.01,1.01,1.02,1.02,1.02,1.02,1.02]

Lifecycle_Operatives = Model.IndShockConsumerType(**Params.init_lifecycle)
Lifecycle_Operatives.cycles = 1 #1 for finite horizon and 0 for infinite horizon
Lifecycle_Operatives.solve()
Lifecycle_Operatives.unpackcFunc()
Lifecycle_Operatives.timeFwd() #make sure that time is moving forward

Params.init_lifecycle["pLvlInitMean"]= -0.0149 #This is set to log(1/1.015) since agents receive their first period permanent income with the growth factor considered.
Params.init_lifecycle['PermGroFac'] = [1.015]*24 + [1.0]*15 + [0.7] + [1]*9     #Solve for Operatives, 1% lower labor income growth

Lifecycle_Operatives_Slower = Model.IndShockConsumerType(**Params.init_lifecycle)
Lifecycle_Operatives_Slower.cycles = 1 #1 for finite horizon and 0 for infinite horizon
Lifecycle_Operatives_Slower.solve()
Lifecycle_Operatives_Slower.unpackcFunc()
Lifecycle_Operatives_Slower.timeFwd() #make sure that time is moving forward


# In[23]:


if do_simulation:
    Lifecycle_Operatives.T_sim = 49 #simulate Lifecycle_Unskilled.T_sim periods for 10000(default) agents
    Lifecycle_Operatives.track_vars = ['aNrmNow','mNrmNow','cNrmNow','pLvlNow','t_age'] #track these variables
    Lifecycle_Operatives.initializeSim()
    Lifecycle_Operatives.simulate()
    
if do_simulation:
    Lifecycle_Operatives_Slower.T_sim = 49 #simulate Lifecycle_Unskilled.T_sim periods for 10000(default) agents
    Lifecycle_Operatives_Slower.track_vars = ['aNrmNow','mNrmNow','cNrmNow','pLvlNow','t_age'] #track these variables
    Lifecycle_Operatives_Slower.initializeSim()
    Lifecycle_Operatives_Slower.simulate()
    
raw_data = {'T_age': Lifecycle_Operatives.t_age_hist.flatten()+24, #add 24 to make the starting period 25. age is same for all occupations so so need to make three of these.
            'aNrmNow_Operatives': Lifecycle_Operatives.aNrmNow_hist.flatten(),
            'aNrmNow_Operatives_Slower': Lifecycle_Operatives_Slower.aNrmNow_hist.flatten(),}

#Make the simulated results into a dataset

Data = pd.DataFrame(raw_data) #make the raw data into a formal dataset

Data['W_Y_Faster'] = Data.aNrmNow_Operatives
Data['W_Y_Slower'] = Data.aNrmNow_Operatives_Slower
AgeMeans = Data.groupby(['T_age']).median().reset_index() # Group the dataset by T_age and get the median.


# In[24]:


plt.figure()

plt.plot(AgeMeans.T_age, AgeMeans.W_Y_Faster,label='Faster Productivity Growth')
plt.plot(AgeMeans.T_age, AgeMeans.W_Y_Slower, label='Slower Productivity Growth',linestyle='--')

plt.legend()
plt.xlabel('Age')
plt.savefig('Figures/Figure7.png')

# In[25]:


#Figure VI

from HARK.ConsumptionSaving.ConsIndShockModel import PerfForesightConsumerType

Params.init_lifecycle["CRRA"]= 2.00            # Default coefficient of relative risk aversion (rho)
Params.init_lifecycle["DiscFac"]= 0.9615         # Default intertemporal discount factor (beta)
Params.init_lifecycle["PermGroFacAgg"]= 1.02    # Aggregate permanent income growth factor 
Params.init_lifecycle["aNrmInitMean"]= -1000       # Mean of log initial assets 
Params.init_lifecycle["aNrmInitStd"]= 0.0      # Standard deviation of log initial assets
Params.init_lifecycle["pLvlInitMean"]= 0.0     # Mean of log initial permanent income 
Params.init_lifecycle["pLvlInitStd"]= 0.0      # Standard deviation of log initial permanent income
Params.init_lifecycle["Rfree"]= 1.08

Params.init_lifecycle['AgentCount'] = 1                 #Change the number of agents simulated from default 10000 to 1000

Params.init_lifecycle['PermShkStd'] = [0]*49              #Originally, [0.1,0.2,0.1,0.2,0.1,0.2,0.1,0,0,0]
Params.init_lifecycle['TranShkStd'] = [0]*49               #Originally, [0.3,0.2,0.1,0.3,0.2,0.1,0.3,0,0,0]
Params.init_lifecycle['LivPrb']     = [1]*49                 #Originally, [0.99,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1]
Params.init_lifecycle['T_cycle']    = 49                     #Life starts at age 25 and ends at 75. Originally 10
Params.init_lifecycle['T_retire']   = 40                    #Agents retire at age 65. Originally 7
Params.init_lifecycle['T_age']      = 50                    #Make sure that old people die at terminal age and don't turn into newborns! Originally 11

Params.init_lifecycle["pLvlInitMean"]= -0.0198
Params.init_lifecycle['PermGroFac'] = [1.025]*24 + [1.01]*15 + [0.7] + [1]*9     #Oringinally, [1.01,1.01,1.01,1.01,1.01,1.02,1.02,1.02,1.02,1.02]

Lifecycle_Operatives_PF = Model.PerfForesightConsumerType(**Params.init_lifecycle)
Lifecycle_Operatives_PF.cycles = 1 #1 for finite horizon and 0 for infinite horizon
Lifecycle_Operatives_PF.solve()
Lifecycle_Operatives_PF.unpackcFunc()
Lifecycle_Operatives_PF.timeFwd() #make sure that time is moving forward

Params.init_lifecycle["pLvlInitMean"]= -0.0149
Params.init_lifecycle['PermGroFac'] = [1.015]*24 + [1.00]*15 + [0.7] + [1]*9     #Oringinally, [1.01,1.01,1.01,1.01,1.01,1.02,1.02,1.02,1.02,1.02]

Lifecycle_Operatives_PF_Slow = Model.PerfForesightConsumerType(**Params.init_lifecycle)
Lifecycle_Operatives_PF_Slow.cycles = 1 #1 for finite horizon and 0 for infinite horizon
Lifecycle_Operatives_PF_Slow.solve()
Lifecycle_Operatives_PF_Slow.unpackcFunc()
Lifecycle_Operatives_PF_Slow.timeFwd() #make sure that time is moving forward


# In[26]:


if do_simulation:
    Lifecycle_Operatives_PF.T_sim = 49 #simulate Lifecycle_Unskilled.T_sim periods for 10000(default) agents
    Lifecycle_Operatives_PF.track_vars = ['aNrmNow','mNrmNow','cNrmNow','pLvlNow','t_age'] #track these variables
    Lifecycle_Operatives_PF.initializeSim()
    Lifecycle_Operatives_PF.simulate()

if do_simulation:
    Lifecycle_Operatives_PF_Slow.T_sim = 49 #simulate Lifecycle_Unskilled.T_sim periods for 10000(default) agents
    Lifecycle_Operatives_PF_Slow.track_vars = ['aNrmNow','mNrmNow','cNrmNow','pLvlNow','t_age'] #track these variables
    Lifecycle_Operatives_PF_Slow.initializeSim()
    Lifecycle_Operatives_PF_Slow.simulate()
    
raw_data = {'T_age': Lifecycle_Operatives_PF.t_age_hist.flatten()+24, #add 24 to make the starting period 25. age is same for all occupations so so need to make three of these.
            'aNrmNow_Operatives': Lifecycle_Operatives_PF.aNrmNow_hist.flatten(),
            'aNrmNow_Operatives_Slow': Lifecycle_Operatives_PF_Slow.aNrmNow_hist.flatten()}

#Make the simulated results into a dataset

Data = pd.DataFrame(raw_data) #make the raw data into a formal dataset
Data['W_Y_PF'] = Data.aNrmNow_Operatives
Data['W_Y_PF_Slow'] = Data.aNrmNow_Operatives_Slow


# In[27]:


plt.figure()

plt.plot(Data.T_age, Data.W_Y_PF,label='Faster Productivity Growth')
plt.plot(Data.T_age, Data.W_Y_PF_Slow,label='Slower Productivity Growth',linestyle='--')

plt.legend()
plt.xlabel('Age')
plt.savefig('Figures/Figure6.png')

# In[28]:


# Define a parameter dictionary with baseline parameter values

# Set the baseline parameter values 
PermGroFac = 1.02
Rfree      = 1
DiscFac    = 0.96
CRRA       = 2.00
UnempPrb   = 0.005
IncUnemp   = 0.0
PermShkStd = 0.1
TranShkStd = 0.1
# Import default parameter values
import HARK.ConsumptionSaving.ConsumerParameters as Params 

# Make a dictionary containing all parameters needed to solve the model
base_params = Params.init_idiosyncratic_shocks

# Set the parameters for the baseline results in the paper
# using the variable values defined in the cell above
base_params['PermGroFac'] = [PermGroFac]   # Permanent income growth factor
base_params['Rfree']      = Rfree          # Interest factor on assets
base_params['DiscFac']    = DiscFac        # Time Preference Factor
base_params['CRRA']       = CRRA           # Coefficient of relative risk aversion
base_params['UnempPrb']   = UnempPrb       # Probability of unemployment (e.g. Probability of Zero Income in the paper)
base_params['IncUnemp']   = IncUnemp       # Induces natural borrowing constraint
base_params['PermShkStd'] = [PermShkStd]   # Standard deviation of log permanent income shocks
base_params['TranShkStd'] = [TranShkStd]   # Standard deviation of log transitory income shocks

# Some technical settings that are not interesting for our purposes
base_params['LivPrb']       = [1.0]   # 100 percent probability of living to next period
base_params['CubicBool']    = True    # Use cubic spline interpolation
base_params['T_cycle']      = 1       # No 'seasonal' cycles
base_params['BoroCnstArt']  = None    # No artificial borrowing constraint


# In[29]:


from HARK.ConsumptionSaving.ConsIndShockModel import IndShockConsumerType
baseEx_inf = IndShockConsumerType(cycles=0,**base_params)

base_params['PermGroFac']=[1.04]
baseEx_infg= IndShockConsumerType(cycles=0,**base_params)

base_params['PermGroFac']=[1.02]
base_params['DiscFac'] = 0.9
baseEx_infd= IndShockConsumerType(cycles=0,**base_params)

baseEx_inf.solve()
baseEx_inf.unpackcFunc()

baseEx_infg.solve()
baseEx_infg.unpackcFunc()

baseEx_infd.solve()
baseEx_infd.unpackcFunc()


# In[30]:


if do_simulation:
    baseEx_inf.T_sim = 100 #simulate Lifecycle_Unskilled.T_sim periods for 10000(default) agents
    baseEx_inf.track_vars = ['aNrmNow','mNrmNow','cNrmNow','pLvlNow','t_age'] #track these variables
    baseEx_inf.initializeSim()
    baseEx_inf.simulate()
    
if do_simulation:
    baseEx_infg.T_sim = 100 #simulate Lifecycle_Unskilled.T_sim periods for 10000(default) agents
    baseEx_infg.track_vars = ['aNrmNow','mNrmNow','cNrmNow','pLvlNow','t_age'] #track these variables
    baseEx_infg.initializeSim()
    baseEx_infg.simulate()

if do_simulation:
    baseEx_infd.T_sim = 100 #simulate Lifecycle_Unskilled.T_sim periods for 10000(default) agents
    baseEx_infd.track_vars = ['aNrmNow','mNrmNow','cNrmNow','pLvlNow','t_age'] #track these variables
    baseEx_infd.initializeSim()
    baseEx_infd.simulate()


# In[31]:


import pandas as pd
raw_data = {'T_age': baseEx_inf.t_age_hist.flatten()+24, #add 24 to make the starting period 25. age is same for all occupations so so need to make three of these.
            'cNrm': baseEx_inf.cNrmNow_hist.flatten(),
            'logcNrm': np.log(baseEx_inf.cNrmNow_hist.flatten()),
            'pLvl': baseEx_inf.pLvlNow_hist.flatten(),
            'logpLvl': np.log(baseEx_inf.pLvlNow_hist.flatten()),
            'mNrm': baseEx_inf.mNrmNow_hist.flatten(),
            'logmNrm': np.log(baseEx_inf.mNrmNow_hist.flatten()),
            'aNrm': baseEx_inf.aNrmNow_hist.flatten(),    
            'cNrmg': baseEx_infg.cNrmNow_hist.flatten(),
            'logcNrmg': np.log(baseEx_infg.cNrmNow_hist.flatten()),
            'pLvlg': baseEx_infg.pLvlNow_hist.flatten(),
            'logpLvlg': np.log(baseEx_infg.pLvlNow_hist.flatten()),
            'mNrmg': baseEx_infg.mNrmNow_hist.flatten(),
            'logmNrmg': np.log(baseEx_infg.mNrmNow_hist.flatten()),
            'aNrmg': baseEx_infg.aNrmNow_hist.flatten(),
            'cNrmd': baseEx_infd.cNrmNow_hist.flatten(),
            'logcNrmd': np.log(baseEx_infd.cNrmNow_hist.flatten()),
            'pLvld': baseEx_infd.pLvlNow_hist.flatten(),
            'logpLvld': np.log(baseEx_infd.pLvlNow_hist.flatten()),
            'mNrmd': baseEx_infd.mNrmNow_hist.flatten(),
            'logmNrmd': np.log(baseEx_infd.mNrmNow_hist.flatten()),
            'aNrmd': baseEx_infd.aNrmNow_hist.flatten()}

#Make the simulated results into a dataset

Data = pd.DataFrame(raw_data) #make the raw data into a formal dataset
Data['Cons'] = Data.cNrm * Data.pLvl #cNrmNow has to be multiplied by pLvlNow
Data['logCons'] = Data.logcNrm + Data.logpLvl
Data['Consg'] = Data.cNrmg * Data.pLvlg #cNrmNow has to be multiplied by pLvlNow
Data['logConsg'] = Data.logcNrmg + Data.logpLvlg
Data['Consd'] = Data.cNrmd * Data.pLvld #cNrmNow has to be multiplied by pLvlNow
Data['logConsd'] = Data.logcNrmd + Data.logpLvld





Data['m'] = Data.mNrm * Data.pLvl
Data['logm'] = Data.logmNrm
Data['mg'] = Data.mNrmg * Data.pLvlg
Data['logmg'] = Data.logmNrmg
Data['md'] = Data.mNrmd * Data.pLvld
Data['logmd'] = Data.logmNrmd



Data['a'] = Data.aNrm * Data.pLvl
Data['ag'] = Data.aNrmg * Data.pLvlg
Data['ad'] = Data.aNrmd * Data.pLvld


Data['Inc'] = Data.pLvl
Data['logInc'] = Data.logpLvl
Data['Incg'] = Data.pLvlg
Data['logIncg'] = Data.logpLvlg
Data['Incd'] = Data.pLvld
Data['logIncd'] = Data.logpLvld








AgeMeans = Data.groupby(['T_age']).mean().reset_index() # Group the dataset by T_age and get the mean.


# In[32]:


import math
table1 = np.zeros((3,7))

#Growth rate of aggregate consumption
table1[0,0] = math.log(AgeMeans.Cons[99]) - math.log(AgeMeans.Cons[98])

#Average growth rate of household permanent income
table1[0,1]=AgeMeans.logpLvl[99]-AgeMeans.logpLvl[98]

#Average growth rate of household consumption
table1[0,2]=AgeMeans.logCons[99]-AgeMeans.logCons[98]

#Aggregate personal saving rate
table1[0,3]=1-(AgeMeans.Cons[99]/(AgeMeans.m[99]-AgeMeans.a[98]))

#Average MPC out of wealth
table1[0,4]=(baseEx_inf.cFunc[0](AgeMeans.mNrm[99]+0.00001) - baseEx_inf.cFunc[0](AgeMeans.mNrm[99]))/0.00001

#Average Net wealth
table1[0,5]=(AgeMeans.mNrm[99] - AgeMeans.cNrm[99])

#Target net wealth
table1[0,6]=baseEx_inf.solution[0].mNrmSS - baseEx_inf.cFunc[0](baseEx_inf.solution[0].mNrmSS)


# In[33]:


#Growth rate of aggregate consumption
table1[1,0]=math.log(AgeMeans.Consg[99]) - math.log(AgeMeans.Consg[98])

#Average growth rate of household permanent income
table1[1,1]=AgeMeans.logpLvlg[99]-AgeMeans.logpLvlg[98]

#Average growth rate of household consumption
table1[1,2]=AgeMeans.logConsg[99]-AgeMeans.logConsg[98]

#Aggregate personal saving rate
table1[1,3]=1-(AgeMeans.Consg[99]/(AgeMeans.mg[99]-AgeMeans.ag[98]))

#Average MPC out of wealth
table1[1,4]=(baseEx_infg.cFunc[0](AgeMeans.mNrmg[99]+0.00001) - baseEx_infg.cFunc[0](AgeMeans.mNrmg[99]))/0.00001

#Average Net wealth
table1[1,5]=(AgeMeans.mNrmg[99] - AgeMeans.cNrmg[99])

#Target net wealth
table1[1,6]=baseEx_infg.solution[0].mNrmSS - baseEx_infg.cFunc[0](baseEx_infg.solution[0].mNrmSS)


# In[34]:


#Growth rate of aggregate consumption
table1[2,0] = math.log(AgeMeans.Consd[99]) - math.log(AgeMeans.Consd[98])

#Average growth rate of household permanent income
table1[2,1]=AgeMeans.logpLvld[99]-AgeMeans.logpLvld[98]

#Average growth rate of household consumption
table1[2,2]=AgeMeans.logConsd[99]-AgeMeans.logConsd[98]

#Aggregate personal saving rate
table1[2,3]=1-(AgeMeans.Consd[99]/(AgeMeans.md[99]-AgeMeans.ad[98]))

#Average MPC out of wealth
table1[2,4]=(baseEx_infd.cFunc[0](AgeMeans.mNrmd[99]+0.00001) - baseEx_infd.cFunc[0](AgeMeans.mNrmd[99]))/0.00001

#Average Net wealth
table1[2,5]=(AgeMeans.mNrmd[99] - AgeMeans.cNrmd[99])

#Target net wealth
table1[2,6]=baseEx_infd.solution[0].mNrmSS - baseEx_infd.cFunc[0](baseEx_infd.solution[0].mNrmSS)


# In[35]:


import pandas as pd


# Data frame of the results we calculated
table = pd.DataFrame(table1)
table.columns = ['Growth rate of aggregate consumption', 'Average growth rate of household permanent income', 'Average growth rate of household consumption', 'Aggregate personal saving rate', 'Average MPC out of wealth','Average net wealth','Target net wealth'] # add names for columns
table.index = ['Base Value','g = .04','depreciation = .10']
table

with open('Tables/table1.tex','w') as tf:
    tf.write(table.to_latex())

# In[36]:


# Define a parameter dictionary with baseline parameter values

# Set the baseline parameter values 
PermGroFac = 1.02
Rfree      = 1.04
DiscFac    = 0.96
CRRA       = 2.00
UnempPrb   = 0.005
IncUnemp   = 0.0
PermShkStd = 0.1
TranShkStd = 0.1
# Import default parameter values
import HARK.ConsumptionSaving.ConsumerParameters as Params 

# Make a dictionary containing all parameters needed to solve the model
base_params = Params.init_idiosyncratic_shocks

# Set the parameters for the baseline results in the paper
# using the variable values defined in the cell above
base_params['PermGroFac'] = [PermGroFac]   # Permanent income growth factor
base_params['Rfree']      = Rfree          # Interest factor on assets
base_params['DiscFac']    = DiscFac        # Time Preference Factor
base_params['CRRA']       = CRRA           # Coefficient of relative risk aversion
base_params['UnempPrb']   = UnempPrb       # Probability of unemployment (e.g. Probability of Zero Income in the paper)
base_params['IncUnemp']   = IncUnemp       # Induces natural borrowing constraint
base_params['PermShkStd'] = [PermShkStd]   # Standard deviation of log permanent income shocks
base_params['TranShkStd'] = [TranShkStd]   # Standard deviation of log transitory income shocks

# Some technical settings that are not interesting for our purposes
base_params['LivPrb']       = [1.0]   # 100 percent probability of living to next period
base_params['CubicBool']    = True    # Use cubic spline interpolation
base_params['T_cycle']      = 1       # No 'seasonal' cycles
base_params['BoroCnstArt']  = None    # No artificial borrowing constraint


# In[37]:


from HARK.ConsumptionSaving.ConsIndShockModel import IndShockConsumerType
baseEx_inf = IndShockConsumerType(cycles=0,**base_params)

base_params['PermGroFac']=[1.03]
baseEx_infg = IndShockConsumerType(cycles=0,**base_params)

baseEx_inf.solve()
baseEx_inf.unpackcFunc()

baseEx_infg.solve()
baseEx_infg.unpackcFunc()


# In[38]:


import HARK.ConsumptionSaving.ConsIndShockModel as Model        # The consumption-saving micro model
import HARK.ConsumptionSaving.ConsumerParameters as Params    # Parameters for the consumer type
from HARK.utilities import plotFuncsDer, plotFuncs              # Some tools
from time import time
mystr = lambda number : "{:.4f}".format(number)
do_simulation = True
import numpy as np
import matplotlib.pyplot as plt


# In[39]:


import math
from scipy.optimize import fsolve

table2 = np.zeros((7,8))
DeltaHW = (1/(1 - 1.03/Rfree)) - (1/(1 - 1.02/Rfree)) #Human wealth difference between two growth rates

for i in range(8):
    table2[i-1,0] = 0.4*i                        #Different Gross wealth ratios
    table2[i-1,4] = baseEx_inf.cFunc[0](0.4*i)   #consumption under 2% permanent income growth rate
    table2[i-1,5] = baseEx_infg.cFunc[0](0.4*i)   #consumption under 3% permanent income growth rate
    table2[i-1,6] = (table2[i-1,5]-table2[i-1,4])/DeltaHW  #MPC out of human wealth
    def func(x):
        return table2[i-1,5]-table2[i-1,4]-(1-(x**(-1)*((x*DiscFac)**(1/CRRA))))*((1/(1-(1.03/x)))-(1/(1-(1.02/x))))
    table2[i-1,7] = fsolve(func, 1.1) -1         # Implied discount rate of future income


# In[40]:


# Define a parameter dictionary with baseline parameter values

# Set the baseline parameter values 
PermGroFac = 1.02
Rfree      = 1.04
DiscFac    = 0.96
CRRA       = 2.00
UnempPrb   = 0.005
IncUnemp   = 0.0
PermShkStd = 0.1
TranShkStd = 0.1
# Import default parameter values
import HARK.ConsumptionSaving.ConsumerParameters as Params 

# Make a dictionary containing all parameters needed to solve the model
base_params = Params.init_idiosyncratic_shocks

# Set the parameters for the baseline results in the paper
# using the variable values defined in the cell above
base_params['PermGroFac'] = [PermGroFac]   # Permanent income growth factor
base_params['Rfree']      = Rfree          # Interest factor on assets
base_params['DiscFac']    = DiscFac        # Time Preference Factor
base_params['CRRA']       = CRRA           # Coefficient of relative risk aversion
base_params['UnempPrb']   = UnempPrb       # Probability of unemployment (e.g. Probability of Zero Income in the paper)
base_params['IncUnemp']   = IncUnemp       # Induces natural borrowing constraint
base_params['PermShkStd'] = [PermShkStd]   # Standard deviation of log permanent income shocks
base_params['TranShkStd'] = [TranShkStd]   # Standard deviation of log transitory income shocks

# Some technical settings that are not interesting for our purposes
base_params['LivPrb']       = [1.0]   # 100 percent probability of living to next period
base_params['CubicBool']    = True    # Use cubic spline interpolation
base_params['T_cycle']      = 1       # No 'seasonal' cycles
base_params['BoroCnstArt']  = None    # No artificial borrowing constraint


# In[41]:


from HARK.ConsumptionSaving.ConsIndShockModel import PerfForesightConsumerType

baseEx_inf_PF = PerfForesightConsumerType(cycles=0,**base_params)

base_params['PermGroFac']=[1.03]
baseEx_inf_PFg = PerfForesightConsumerType(cycles=0,**base_params)

baseEx_inf_PF.solve()
baseEx_inf_PF.unpackcFunc()

baseEx_inf_PFg.solve()
baseEx_inf_PFg.unpackcFunc()


# In[42]:


for i in range(8):
    table2[i-1,1] = baseEx_inf_PF.cFunc[0](0.4*i)           #Consumption in certainty model when permanent income growth rate is 2%
    table2[i-1,2] = baseEx_inf_PFg.cFunc[0](0.4*i)          #Consumption in certainty model when permanent income growth rate is 3%
    table2[i-1,3] = (table2[i-1,2] - table2[i-1,1])/DeltaHW #MPC out of human wealth in certainty model


# In[43]:


import pandas as pd



# Data frame of the results we calculated
table = pd.DataFrame(table2)
table.columns = ['Gross wealth ratio', 'Consumption when g=2%', 'Consumption when g=3%', 'MPC out of human wealth','Consumption when g=2%', 'Consumption when g=3%', 'MPC out of human wealth', 'Implied Discount Rate of Future Income'] # add names for columns
table.index =['','','','','','','']
table
with open('Tables/table2.tex','w') as tf:
    tf.write(table.to_latex())
